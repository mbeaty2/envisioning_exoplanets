{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Datasets for Training\n",
    "\n",
    "In this notebook, we will create prepare our dataset to train our model with. These datasets will have two columns: \n",
    "* one for the image links\n",
    "* one for the image name (once saved)\n",
    "* one for the captions (this will actually be several columns as we have several prompts we want to train our model with)\n",
    "\n",
    "The different captions or prompts we will use are:\n",
    "* mass_prompt: using numerical values of planet and star mass in relation to our earth and sun.\n",
    "* ratio_prompt: using a comparison between size of star and planet to represent size.\n",
    "* size_text_prompt: using text comparisons for planet and star size.\n",
    "* shorter_prompt: a reduced version of the prompt to simpler phrases.\n",
    "* 75_tokens: an even shorter version of the prompts to only 75 tokens, which is the only length that can fine-tune stable diffusion without altering the text encoder. (This might replace the shorter_prompt option.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is resize all of our images to 512 x 512 and save the images to a folder called \"data\". All of the images currently are web-links. So we need to read them, resize them, and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the dataset we'll be working with\n",
    "dataset = pd.read_csv(\"training_data_prompts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need the image link and the prompts, so we are going to isolate these from the whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataset[['image_link', 'mass_prompt', 'ratio_prompt', 'size_text_prompt', 'shorter_prompt', '75_tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the image from the dataset\n",
    "data_folder = 'data_huggingface'\n",
    "os.makedirs(data_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, data in training_data.iterrows():\n",
    "    image_url = data['image_link']  \n",
    "\n",
    "    # Getting the Image and opening it using PIL\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "\n",
    "    # Resize the image to 512x512\n",
    "    img_resized = img.resize((512, 512))\n",
    "\n",
    "    # Save the resized image to the 'data' folder\n",
    "    image_path = os.path.join(data_folder, f'image_{index + 1}.jpg')\n",
    "    img_resized.save(image_path)\n",
    "\n",
    "    # Update the dataset with the image path\n",
    "    training_data.at[index, 'image_path'] = image_path\n",
    "\n",
    "# Save the updated DataFrame with image paths\n",
    "training_data.to_csv('updated_training_data_prompts.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another training resource uses a json dataframe to train, so we are going to set up our code to do this in the format needed for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_training_data = pd.read_csv('updated_training_data_prompts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dict = {}\n",
    "\n",
    "for index, data in updated_training_data.iterrows():\n",
    "    image_path = data['image_path'].split(\"/\")[1].split(\".\")[0]\n",
    "    metadata = {\"tags\": \"solo, no humans, space, starry night\", \n",
    "                \"caption\": data[\"75_tokens\"]}\n",
    "\n",
    "    metadata_dict[image_path] = metadata\n",
    "\n",
    "with open(\"metadata.json\", \"w\") as json_file:\n",
    "    json.dump(metadata_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metadata.jsonl\", \"w\") as json_file:\n",
    "    for index, data in updated_training_data.iterrows():\n",
    "        image_path = data['image_path'].split(\"/\")[1]\n",
    "        #print(image_path)\n",
    "        metadata = {\n",
    "            \"file_name\": image_path, \"text\": data[\"75_tokens\"]\n",
    "        }\n",
    "        #print(metadata)\n",
    "        json.dump(metadata, json_file)\n",
    "        json_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.DataFrame()\n",
    "for index, data in updated_training_data.iterrows():\n",
    "    image_path = data['image_path'].split(\"/\")[1]\n",
    "    #print(image_path)\n",
    "    metadata.at[index, \"file_name\"] = image_path\n",
    "    metadata.at[index, \"text\"] = data[\"75_tokens\"]\n",
    "    \n",
    "metadata.to_csv('metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, data in updated_training_data.iterrows():\n",
    "    image_path = data['image_path'].split(\"/\")[1].split(\".\")[0]\n",
    "    text = data['75_tokens']\n",
    "\n",
    "    txt_file_path = f'{image_path}.txt'\n",
    "\n",
    "    with open(txt_file_path, 'w') as txt_file:\n",
    "        txt_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('imagefolder', data_dir='data_huggingface', drop_labels=False, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_hub(\"mbeaty2/exoplanet-data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05aa552c7d7658e2167e00b3eafb271c02ebfc9b6405c32b454575423e68a7f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
